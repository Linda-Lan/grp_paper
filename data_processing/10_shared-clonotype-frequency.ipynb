{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared clonotype frequency\n",
    "\n",
    "For every groupwise combination of two or more subjects, compute the frequency of universally shared clonotypes (that is, clonotypes found in the repertoire of every member in the group).\n",
    "\n",
    "The following Python packages are required to run the code in this notebook:\n",
    "  * numpy\n",
    "  * pandas\n",
    "  * [abutils](https://github.com/briney/abutils)\n",
    "\n",
    "They can be install by running `pip install numpy pandas abutils`\n",
    "\n",
    "*NOTE: this notebook requires the use of the Unix command line tool `wc`. Thus, it requires a Unix-based operating system to run correctly (MacOS and most flavors of Linux should be fine). Running this notebook on Windows 10 may be possible using the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/about) but we have not tested this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abutils.utils.jobs import monitor_mp_jobs\n",
    "from abutils.utils.pipeline import list_files, make_dir\n",
    "from abutils.utils.progbar import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjects, files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files and directories\n",
    "dedup_subject_dir = './data/dedup_subject_clonotype_pools/'\n",
    "cross_subject_occurance_files = list_files('./data/cross-subject_clonotype_duplicate-counts/')\n",
    "\n",
    "# subjects\n",
    "with open('./data/subjects.txt') as f:\n",
    "    subjects = sorted(f.read().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique clonotypes per subject\n",
    "\n",
    "If you'd like to actually count the number of unique clonotypes per subject, you can run the code in [**this**](LINK) notebook or download a dataset containing each subject's unique clonotypes [**here**](LINK). Note that the decompressed unique clonotype dataset is fairly large (about 8GB). \n",
    "\n",
    "All we're doing is counting the number of lines in the unique clonotype file. If you'd rather not download and decompress the data just to count the lines, skip the next block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_sizes = {}\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    dedup_file = os.path.join(dedup_subject_dir, '{}_dedup_pool_vj-aa.txt'.format(subject))\n",
    "    wc_cmd = 'wc -l {}'.format(dedup_file)\n",
    "    p = sp.Popen(wc_cmd, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    size = int(stdout.strip().split()[0])\n",
    "    subject_sizes[subject] = size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run the following code block if you skipped the previous one. This loads pre-computed unique clonotype counts for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/unique_clonotype_counts.json') as f:\n",
    "    subject_sizes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify shared clonotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023/1023) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%  (00:01)  "
     ]
    }
   ],
   "source": [
    "shared_frequencies_by_group_size = {i + 1: [] for i in range(len(subjects))}\n",
    "shared_frequencies_by_group = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "progress_bar(0, len(cross_subject_occurance_files), start_time=start_time)\n",
    "\n",
    "for i, of in enumerate(cross_subject_occurance_files):\n",
    "    _subjects = os.path.basename(of).split('_')[0].split('-')\n",
    "    smallest = min([subject_sizes[s] for s in _subjects])\n",
    "    min_freq = str(len(_subjects))\n",
    "    with open(of) as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            if line.strip().split()[0] == min_freq:\n",
    "                count = int(line.strip().split()[1])\n",
    "                break\n",
    "    frequency = 1. * count / smallest\n",
    "    shared_frequencies_by_group.append('{}: {}'.format(', '.join(_subjects), 100. * frequency))\n",
    "    shared_frequencies_by_group_size[len(_subjects)].append(frequency)\n",
    "    progress_bar(i + 1, len(cross_subject_occurance_files), start_time=start_time)\n",
    "\n",
    "with open('./data/shared_clonotypes/groupwise_shared_clonotype_frequencies.txt', 'w') as f:\n",
    "    f.write('\\n'.join(shared_frequencies_by_group))\n",
    "    \n",
    "with open('./data/shared_clonotypes/groupwise_shared_clonotype_frequencies_by-size.json', 'w') as f:\n",
    "    json.dump(shared_frequencies_by_group_size, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
