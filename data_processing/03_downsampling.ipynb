{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clonotype and sequence downsampling\n",
    "\n",
    "For a variety of downstream analyses (rarefaction, repeat observation frequency, diversity estimation, etc), we need a set of downsampled clonotype and sequence datasets for each subject. Because we obtained a different number of sequences for each subject, the downsample sizes are relative to the total size of each subject's dataset (intervals of 10% of the total dataset).\n",
    "\n",
    "The [`abutils`](https://www.github.com/briney/abutils) Python package is required for this notebook, and can be installed by running `pip install abutils`.\n",
    "\n",
    "*NOTE: this notebook requires the use of several Unix command line tools, including `cat`, `shuf`, `sort` and `uniq`. Thus, it requires a Unix-based operating system to run correctly (MacOS and most flavors of Linux should be fine). Running this notebook on Windows 10 may be possible using the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/about) but we have not tested this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from abutils.utils.jobs import monitor_mp_jobs\n",
    "from abutils.utils.pipeline import list_files, make_dir\n",
    "from abutils.utils.progbar import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjects and directories\n",
    "\n",
    "The input directories should contain deduplicated clonotypes or sequences. You can generate the deduplicated clonotype/sequence files using [**this**](LINK) Jupyter notebook, or you can download the deduplicated clontype data [**here**](LINK) and the deduplicated sequence data [**HERE**](LINK). If downloading the data (which will be downloaded as a compressed archive), decompress the archive in the `data` directory (in the same parent directory as this notebook) and you should be ready to go. If you want to store the deduplicated sequence data in some other location, adjust `input_clonotype_dir` and /or `input_sequence_dir` paths below as needed.\n",
    "\n",
    "`iterations` is the number of replicate downsamplings (without replacement) that will be performed at each subsample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects\n",
    "with open('./data/subjects.txt') as f:\n",
    "    subjects = sorted(f.read().split())\n",
    "\n",
    "# iterations\n",
    "iterations = 10\n",
    "    \n",
    "# directories\n",
    "input_clonotype_dir = './data/dedup_techrep-merged_vj-aa/'\n",
    "input_sequence_dir = './data/dedup_techrep-merged_nt-seq/'\n",
    "project_dir = './data/equal_fraction_downsampling/'\n",
    "make_dir(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(input_files, downsample_size):\n",
    "    counts = {}\n",
    "    uniq_cmd = 'cat {} | shuf -n {} | sort -T /data/temp_dir/ | uniq -c'.format(' '.join(input_files), downsample_size)\n",
    "    p = sp.Popen(uniq_cmd, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    for line in stdout.split('\\n'):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        count = int(line.split()[0])\n",
    "        if count not in counts:\n",
    "            counts[count] = 1\n",
    "        else:\n",
    "            counts[count] += 1\n",
    "    return counts\n",
    "\n",
    "def get_combined_sequence_count(files):\n",
    "    wc_cmd = 'cat {} | wc -l'.format(' '.join(files))\n",
    "    p = sp.Popen(wc_cmd, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    return int(stdout.strip().split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clonotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the counts file\n",
    "counts_file = os.path.join(project_dir, 'clonotype-downsampling_duplicate-counts_vj-aa.txt')\n",
    "with open(counts_file, 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "# initialize multiprocessing\n",
    "p = mp.Pool(maxtasksperchild=1)\n",
    "\n",
    "for subject in subjects:\n",
    "    # print header\n",
    "    print('=' * (len(subject) + 4))\n",
    "    print('  ' + subject)\n",
    "    print('=' * (len(subject) + 4))\n",
    "    print('')\n",
    "    with open(counts_file, 'a') as f:\n",
    "        f.write('#{}\\n'.format(subject))\n",
    "        \n",
    "    # get the combined number of unique clonotype sequences\n",
    "    input_files = list_files(os.path.join(input_clonotype_dir, subject))\n",
    "    total_size = get_combined_sequence_count(input_files)\n",
    "    \n",
    "    # process the iterations of each downsample size in parallel\n",
    "    for fraction in np.arange(0.1, 1.01, 0.1):\n",
    "        downsample_size = int(round(float(total_size) * fraction, 0))\n",
    "        with open(counts_file, 'a') as f:\n",
    "            f.write('>{}\\n'.format(fraction))\n",
    "        async_results = []\n",
    "        print('Subsample:', fraction, '({})'.format(downsample_size))\n",
    "        for i in range(1, iterations + 1):\n",
    "            async_results.append(p.apply_async(downsample, args=(input_files, downsample_size)))\n",
    "        monitor_mp_jobs(async_results)\n",
    "        results = [ar.get() for ar in async_results]\n",
    "        for counts in results:\n",
    "            ostring = ' '.join(['{}:{}'.format(k, counts[k]) for k in sorted(counts.keys())])\n",
    "            with open(counts_file, 'a') as f:\n",
    "                f.write('{}\\n'.format(ostring))\n",
    "        print('')\n",
    "    print('\\n')\n",
    "\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the counts file\n",
    "counts_file = os.path.join(project_dir, 'sequence-downsampling_duplicate-counts_nt-seq.txt')\n",
    "with open(counts_file, 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "# initialize multiprocessing\n",
    "p = mp.Pool(maxtasksperchild=1)\n",
    "\n",
    "for subject in subjects:\n",
    "    # print header\n",
    "    print('=' * (len(subject) + 4))\n",
    "    print('  ' + subject)\n",
    "    print('=' * (len(subject) + 4))\n",
    "    print('')\n",
    "    with open(counts_file, 'a') as f:\n",
    "        f.write('#{}\\n'.format(subject))\n",
    "        \n",
    "    # get the combined number of unique clonotype sequences\n",
    "    input_files = list_files(os.path.join(input_sequence_dir, subject))\n",
    "    total_size = get_combined_sequence_count(input_files)\n",
    "    \n",
    "    # process the iterations of each downsample size in parallel\n",
    "    for fraction in np.arange(0.1, 1.01, 0.1):\n",
    "        downsample_size = int(round(float(total_size) * fraction, 0))\n",
    "        with open(counts_file, 'a') as f:\n",
    "            f.write('>{}\\n'.format(fraction))\n",
    "        async_results = []\n",
    "        print('Subsample:', fraction, '({})'.format(downsample_size))\n",
    "        for i in range(1, iterations + 1):\n",
    "            async_results.append(p.apply_async(downsample, args=(input_files, downsample_size)))\n",
    "        monitor_mp_jobs(async_results)\n",
    "        results = [ar.get() for ar in async_results]\n",
    "        for counts in results:\n",
    "            ostring = ' '.join(['{}:{}'.format(k, counts[k]) for k in sorted(counts.keys())])\n",
    "            with open(counts_file, 'a') as f:\n",
    "                f.write('{}\\n'.format(ostring))\n",
    "        print('')\n",
    "    print('\\n')\n",
    "\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
